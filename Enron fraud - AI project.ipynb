{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enron Fraud Indentification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose of this project is using machine learning algorithm to detect fraudsters. Those persons are main criminals in Enron scandal. We would like to make a learning model to predict those people by using multiple variables which are reported in financial sheets and emailling list. Because we have already know person of interests (POI), we could use supervised machine learning to do this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "import tester\n",
    "\n",
    "import tester\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from tabulate import tabulate\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "target_list = ['poi']\n",
    "report_list = ['salary','deferral_payments', 'total_payments',\n",
    "               'loan_advances', 'bonus', 'restricted_stock_deferred', \n",
    "               'deferred_income', 'total_stock_value', 'expenses',\n",
    "               'exercised_stock_options', 'other', 'long_term_incentive', \n",
    "               'restricted_stock', 'director_fees','to_messages',\n",
    "               'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi', \n",
    "               'shared_receipt_with_poi']\n",
    "features_list =  target_list + report_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "counter = 0\n",
    "for entry in my_dataset:\n",
    "    if my_dataset[entry]['poi']:\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in this dataset: 146.000000\n",
      "Number of POI in this dataset: 18.000000\n",
      "Number of feature in this dataset: 20.000000\n"
     ]
    }
   ],
   "source": [
    "print 'Number of data points in this dataset: %f' %len(my_dataset)\n",
    "print 'Number of POI in this dataset: %f' %counter\n",
    "print 'Number of feature in this dataset: %f' %len(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are total 18 POIs in total 146 data points. Next step will be the data auditing to determine missing values or outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Feature  No of Missing Values\n",
      "11              loan_advances                   142\n",
      "6               director_fees                   129\n",
      "7   restricted_stock_deferred                   128\n",
      "2           deferral_payments                   107\n",
      "15            deferred_income                    97\n",
      "18        long_term_incentive                    80\n",
      "5                       bonus                    64\n",
      "16    shared_receipt_with_poi                    60\n",
      "14    from_this_person_to_poi                    60\n",
      "1                 to_messages                    60\n",
      "10    from_poi_to_this_person                    60\n",
      "12              from_messages                    60\n",
      "13                      other                    53\n",
      "0                      salary                    51\n",
      "9                    expenses                    51\n",
      "4     exercised_stock_options                    44\n",
      "17           restricted_stock                    36\n",
      "3              total_payments                    21\n",
      "8           total_stock_value                    20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:10: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "### Determine missing values in Enron report\n",
    "value_report_list = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "dict_report_list = dict(zip(report_list,value_report_list))\n",
    "for entry in my_dataset:\n",
    "    for name in report_list:\n",
    "        val = my_dataset[entry][name]\n",
    "        if val == 'NaN':\n",
    "            dict_report_list[name] += 1\n",
    "NaN_table = pd.DataFrame(dict_report_list.items(), columns=['Feature', 'No of Missing Values'])\n",
    "print NaN_table.sort(columns = 'No of Missing Values',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through above table, every features except 'poi' has missing values at least 20 times. Top 3 features that have highest missing values are 'loan_advance', 'director_fees' and 'restricted_stock_deferred'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Enron printed sheet, I found two outlier that is \"TOTAL\" and \"THE TRAVEL AGENCY IN THE PARK\". \n",
    "- \"TOTAL\" is the summary of every column in Enron sheet and it is a spreadsheet quirk.\n",
    "- \"THE TRAVEL AGENCY IN THE PARK\" is the account of business-related travel to The Travel Agency in the Park. It is not a person of interest.\n",
    "\n",
    "Another possibility is the observation with no information (all \"NaN\" value) which will determined by the script beblow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outlier list is: \n",
      "['LOCKHART EUGENE E', 'TOTAL', 'THE TRAVEL AGENCY IN THE PARK']\n"
     ]
    }
   ],
   "source": [
    "outlier_list = []\n",
    "#### Next script is used to remove observation which have all value 'NaN' in Enron report. \n",
    "for entry in my_dataset:\n",
    "    for name in report_list:\n",
    "        val = my_dataset[entry][name]\n",
    "        if val == 'NaN':\n",
    "            if entry not in outlier_list:\n",
    "                outlier_list.append(entry)\n",
    "        elif val != 'NaN':\n",
    "            try:\n",
    "                outlier_list.remove(entry)\n",
    "                break\n",
    "            except ValueError:\n",
    "                break\n",
    "\n",
    "outlier_list.append('TOTAL') #insert 'TOTAL' observation\n",
    "outlier_list.append('THE TRAVEL AGENCY IN THE PARK')\n",
    "print 'The outlier list is: '\n",
    "print outlier_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points after outlier removing in this dataset: 143.000000\n"
     ]
    }
   ],
   "source": [
    "#### Remove outlier\n",
    "for name in outlier_list:\n",
    "    my_dataset.pop(name,0)\n",
    "print 'Number of data points after outlier removing in this dataset: %f' %len(my_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the Enron report, we have the email list of Enron POI and non-POI. It will be smart to create a new feature based on the ratio between to/from POI and to/from a person. There is a chance that they can be used in POI prediction later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poi', 'salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', 'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock', 'director_fees', 'to_messages', 'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi', 'shared_receipt_with_poi', 'fraction_from_poi', 'fraction_to_poi']\n"
     ]
    }
   ],
   "source": [
    "#### Making new feature based on other features.\n",
    "def computeFraction( poi_messages, all_messages ):\n",
    "    \"\"\" given a number messages to/from POI (numerator) \n",
    "        and number of all messages to/from a person (denominator),\n",
    "        return the fraction of messages to/from that person\n",
    "        that are from/to a POI\n",
    "   \"\"\"\n",
    "   \n",
    "    ### you fill in this code, so that it returns either\n",
    "    ###     the fraction of all messages to this person that come from POIs\n",
    "    ###     or\n",
    "    ###     the fraction of all messages from this person that are sent to POIs\n",
    "    ### the same code can be used to compute either quantity\n",
    "\n",
    "    ### beware of \"NaN\" when there is no known email address (and so\n",
    "    ### no filled email features), and integer division!\n",
    "    ### in case of poi_messages or all_messages having \"NaN\" value, return 0.\n",
    "    if poi_messages == \"NaN\":\n",
    "        fraction = 0.\n",
    "    elif all_messages == \"NaN\":\n",
    "        fraction = 0.\n",
    "    else:\n",
    "        fraction = poi_messages*1.0/all_messages\n",
    "\n",
    "    return fraction\n",
    "\n",
    "for name in my_dataset:\n",
    "    data_point = my_dataset[name]\n",
    "    from_poi_to_this_person = data_point[\"from_poi_to_this_person\"]\n",
    "    to_messages = data_point[\"to_messages\"]\n",
    "    fraction_from_poi = computeFraction( from_poi_to_this_person, to_messages )\n",
    "    my_dataset[name][\"fraction_from_poi\"] = fraction_from_poi\n",
    "\n",
    "    from_this_person_to_poi = data_point[\"from_this_person_to_poi\"]\n",
    "    from_messages = data_point[\"from_messages\"]\n",
    "    fraction_to_poi = computeFraction( from_this_person_to_poi, from_messages )\n",
    "    my_dataset[name][\"fraction_to_poi\"] = fraction_to_poi\n",
    "\n",
    "### Feature list with addtional features\n",
    "features_list = features_list + ['fraction_from_poi','fraction_to_poi']\n",
    "print features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to determine the best features for prediction, I have used 'SelectKBest' function to evaluate the importance of each features. The function was applied in training set created by 'train_test_split' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Feature      Score\n",
      "0     exercised_stock_options  24.815080\n",
      "1           total_stock_value  24.182899\n",
      "2                       bonus  20.792252\n",
      "3                      salary  18.289684\n",
      "4             fraction_to_poi  16.409713\n",
      "5             deferred_income  11.458477\n",
      "6         long_term_incentive   9.922186\n",
      "7            restricted_stock   9.212811\n",
      "8              total_payments   8.772778\n",
      "9     shared_receipt_with_poi   8.589421\n",
      "10              loan_advances   7.184056\n",
      "11                   expenses   6.094173\n",
      "12    from_poi_to_this_person   5.243450\n",
      "13                      other   4.187478\n",
      "14          fraction_from_poi   3.128092\n",
      "15    from_this_person_to_poi   2.382612\n",
      "16              director_fees   2.126328\n",
      "17                to_messages   1.646341\n",
      "18          deferral_payments   0.224611\n",
      "19              from_messages   0.169701\n",
      "20  restricted_stock_deferred   0.065500\n"
     ]
    }
   ],
   "source": [
    "### Using SelectKBest to determine number of selection feature.\n",
    "SKB = SelectKBest()\n",
    "SKB.fit(features,labels)\n",
    "scores = SKB.scores_\n",
    "unsorted_pairs = zip(features_list[1:], scores)\n",
    "sorted_pairs = list(reversed(sorted(unsorted_pairs, key=lambda x: x[1])))\n",
    "KBest_table = pd.DataFrame(sorted_pairs,columns=['Feature','Score'])\n",
    "print KBest_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAGCCAYAAADniqieAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc61add8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(KBest_table['Feature'],KBest_table['Score'])\n",
    "_, labels = plt.xticks()\n",
    "plt.setp(labels, rotation=90)\n",
    "plt.ylabel('SKBest score')\n",
    "plt.title('Classifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the result of SelectKBest, I selected 6 features of interest since they have highest impact for the model fitting (score > 10). Clearly, we see that our new feature \"fraction_to_poi\" has high impact on the data model when it is at top 5th. Would this enginereed variable affect the validation of POIs in classifer ? To answer this question, I made an classifer testing with two feature lists: original list (without 'fraction_to_poi') and engineered list (with 'fraction_to_poi')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poi', 'exercised_stock_options', 'total_stock_value', 'bonus', 'salary', 'deferred_income']\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.95      0.95        39\n",
      "        1.0       0.33      0.33      0.33         3\n",
      "\n",
      "avg / total       0.90      0.90      0.90        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Validate the original feature list in Naive Bayes classifier\n",
    "old_features_list = target_list + list(KBest_table['Feature'].iloc[:6])\n",
    "old_features_list.remove('fraction_to_poi')\n",
    "print old_features_list\n",
    "# Re-create the data for model fitting\n",
    "data = featureFormat(my_dataset, old_features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "# Example starting point. Create train and test set from original dataset. 30% of data goes into test set.\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "    \n",
    "clf_NB = GaussianNB()\n",
    "clf_NB.fit(features_train,labels_train)\n",
    "labels_pred = clf_NB.predict(features_test)\n",
    "print classification_report(labels_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poi', 'exercised_stock_options', 'total_stock_value', 'bonus', 'salary', 'fraction_to_poi', 'deferred_income']\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.94      0.93        36\n",
      "        1.0       0.60      0.50      0.55         6\n",
      "\n",
      "avg / total       0.87      0.88      0.88        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Validate the engineered feature list in Naive Bayes classifier\n",
    "new_features_list = target_list + list(KBest_table['Feature'].iloc[:6])\n",
    "print new_features_list\n",
    "# Re-create the data for model fitting\n",
    "data = featureFormat(my_dataset, new_features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "# Example starting point. Create train and test set from original dataset. 30% of data goes into test set.\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "    \n",
    "clf_NB = GaussianNB()\n",
    "clf_NB.fit(features_train,labels_train)\n",
    "labels_pred = clf_NB.predict(features_test)\n",
    "print classification_report(labels_test, labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision and recall scores of my engineered list is higher than original list in POI detection (class 1). So I suggested to include 'fraction_to_poi' in feature set used for further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name               Precision    Recall\n",
      "---------------  -----------  --------\n",
      "Original List           0.33      0.33\n",
      "Engineered list         0.6       0.5\n"
     ]
    }
   ],
   "source": [
    "print tabulate([['Original List', 0.33, 0.33], ['Engineered list', 0.60, 0.50]], headers=['Name', 'Precision','Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, new_features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "# Example starting point. Create train and test set from original dataset. 30% of data goes into test set.\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Reshape the training and test sets.\n",
    "features_train = np.array(features_train)\n",
    "labels_train = np.array(labels_train)\n",
    "features_test = np.array(features_test)\n",
    "labels_test = np.array(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many classifiers for classification. For the purpose of this porject and time saving, I only picked 6 common models for data fitting. I created pipeline that includes Scaling, Feature Selection, Principle Component Analysis (PCA) and Classifiers. I had to use feature scaling because some model need that processing.\n",
    "\n",
    "Through running defaut model with 6 features of interest, their 'f1' scores were compared after running 'tester.py' . The reason for chosing 'f1' because it is the weighted average of Precision and Recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\n",
      "Naive Bayes\n",
      "Fit to training dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.92      0.92        36\n",
      "        1.0       0.50      0.50      0.50         6\n",
      "\n",
      "avg / total       0.86      0.86      0.86        42\n",
      "\n",
      "\t\n",
      "Test on tester.py\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('SKB', SelectKBest(k=6, score_func=<function f_classif at 0x0000000007B63F98>)), ('CLF', GaussianNB())])\n",
      "\tAccuracy: 0.85236\tPrecision: 0.47723\tRecall: 0.35100\tF1: 0.40449\tF2: 0.37061\n",
      "\tTotal predictions: 14000\tTrue positives:  702\tFalse positives:  769\tFalse negatives: 1298\tTrue negatives: 11231\n",
      "\n",
      "None\n",
      "done in 2.235s\n",
      "\t\n",
      "Support Vector Machine\n",
      "Fit to training dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      1.00      0.92        36\n",
      "        1.0       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.73      0.86      0.79        42\n",
      "\n",
      "\t\n",
      "Test on tester.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got a divide by zero when trying out: Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('SKB', SelectKBest(k=6, score_func=<function f_classif at 0x0000000007B63F98>)), ('CLF', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Precision or recall may be undefined due to a lack of true positive predicitons.\n",
      "None\n",
      "done in 2.101s\n",
      "\t\n",
      "Decision Tree\n",
      "Fit to training dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.89      0.90        36\n",
      "        1.0       0.43      0.50      0.46         6\n",
      "\n",
      "avg / total       0.84      0.83      0.84        42\n",
      "\n",
      "\t\n",
      "Test on tester.py\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('SKB', SelectKBest(k=6, score_func=<function f_classif at 0x0000000007B63F98>)), ('CLF', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'))])\n",
      "\tAccuracy: 0.79071\tPrecision: 0.26912\tRecall: 0.27100\tF1: 0.27005\tF2: 0.27062\n",
      "\tTotal predictions: 14000\tTrue positives:  542\tFalse positives: 1472\tFalse negatives: 1458\tTrue negatives: 10528\n",
      "\n",
      "None\n",
      "done in 2.007s\n",
      "\t\n",
      "KNN\n",
      "Fit to training dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.94      0.89        36\n",
      "        1.0       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.73      0.81      0.77        42\n",
      "\n",
      "\t\n",
      "Test on tester.py\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('SKB', SelectKBest(k=6, score_func=<function f_classif at 0x0000000007B63F98>)), ('CLF', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'))])\n",
      "\tAccuracy: 0.83514\tPrecision: 0.23448\tRecall: 0.06800\tF1: 0.10543\tF2: 0.07925\n",
      "\tTotal predictions: 14000\tTrue positives:  136\tFalse positives:  444\tFalse negatives: 1864\tTrue negatives: 11556\n",
      "\n",
      "None\n",
      "done in 2.417s\n",
      "\t\n",
      "RandomForest\n",
      "Fit to training dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.89      0.92      0.90        36\n",
      "        1.0       0.40      0.33      0.36         6\n",
      "\n",
      "avg / total       0.82      0.83      0.83        42\n",
      "\n",
      "\t\n",
      "Test on tester.py\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('SKB', SelectKBest(k=6, score_func=<function f_classif at 0x0000000007B63F98>)), ('CLF', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None...n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))])\n",
      "\tAccuracy: 0.85629\tPrecision: 0.49239\tRecall: 0.19400\tF1: 0.27834\tF2: 0.22076\n",
      "\tTotal predictions: 14000\tTrue positives:  388\tFalse positives:  400\tFalse negatives: 1612\tTrue negatives: 11600\n",
      "\n",
      "None\n",
      "done in 27.533s\n",
      "\t\n",
      "AdaBoost\n",
      "Fit to training dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.92      0.92        36\n",
      "        1.0       0.50      0.50      0.50         6\n",
      "\n",
      "avg / total       0.86      0.86      0.86        42\n",
      "\n",
      "\t\n",
      "Test on tester.py\n",
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('SKB', SelectKBest(k=6, score_func=<function f_classif at 0x0000000007B63F98>)), ('CLF', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None))])\n",
      "\tAccuracy: 0.82414\tPrecision: 0.35154\tRecall: 0.27350\tF1: 0.30765\tF2: 0.28621\n",
      "\tTotal predictions: 14000\tTrue positives:  547\tFalse positives: 1009\tFalse negatives: 1453\tTrue negatives: 10991\n",
      "\n",
      "None\n",
      "done in 118.370s\n"
     ]
    }
   ],
   "source": [
    "### Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "#### Checking the final result with all ML that are used for classification:\n",
    "#### Using GridSearchCV to optimize number of features + SelectKBest\n",
    "#### Create cross-validation  \n",
    "sss = StratifiedShuffleSplit(labels_train, 50, test_size = 0.3, random_state = 42)\n",
    "mm_scaler = MinMaxScaler()\n",
    "\n",
    "name_list = ['Naive Bayes',\n",
    "             'Support Vector Machine',\n",
    "             'Decision Tree',\n",
    "             'KNN',\n",
    "             'RandomForest','AdaBoost'\n",
    "            ]\n",
    "clf_list = [GaussianNB(),\n",
    "            SVC(),\n",
    "            DecisionTreeClassifier(),\n",
    "            KNeighborsClassifier(),\n",
    "            RandomForestClassifier(),\n",
    "            AdaBoostClassifier()\n",
    "           ]\n",
    "\n",
    "for name, clf in zip(name_list,clf_list):\n",
    "    t0 = time() \n",
    "    pipe = Pipeline(steps =[('scaler',mm_scaler),('SKB',SelectKBest(k = 6)),('CLF',clf)])\n",
    "    pipe.fit(features_train,labels_train)\n",
    "    labels_pred = pipe.predict(features_test)\n",
    "    clf_final = pipe\n",
    "    #clf_final = pipe\n",
    "    print '\\t'\n",
    "    print name\n",
    "    print 'Fit to training dataset'\n",
    "    print classification_report(labels_test, labels_pred)    \n",
    "    print '\\t'\n",
    "    print 'Test on tester.py'\n",
    "    f1 = tester.test_classifier(clf_final, my_dataset, new_features_list)\n",
    "    print f1\n",
    "    print \"done in %0.3fs\" % (time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAFtCAYAAAADA82kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxGBmZjlODGZmlvP/AfqzDMr2foPRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc7c05f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Create array for f1\n",
    "f1_score = [0.40449,0.0,0.27005,0.10543,0.27834,0.30765]\n",
    "\n",
    "name_list = ('Naive Bayes','Support Vector Machine',\n",
    "             'Decision Tree','K-NN',\n",
    "             'RandomForest','AdaBoost')\n",
    "\n",
    "plt.bar(np.arange(len(name_list)),f1_score,align='center', color = 'rgbkymc',alpha = 0.5)\n",
    "plt.xticks(np.arange(len(name_list)), name_list, rotation = 90)\n",
    "plt.ylabel('F1 score')\n",
    "plt.title('Classifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found that Naive Bayes model had the highest F1-score. I decided to select Naive Bayes and Decision Tree for my model optimization. The final model is the one which highest F1 after parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this task is trying to optimize model fitting in order to obtain at least 0.3 in both precision and recall using testing script. \n",
    "\n",
    "The strategy for tuning is using GridSearchCV to optimize parameters from each models and apply cross-validation to determine the best F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My strategy is to optimize:\n",
    "- The number of features: SelectKBest(k = 5,6)\n",
    "- The number of components: PCA(n_components = 2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Create cross-validation\n",
    "sss = StratifiedShuffleSplit(labels, 50, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scale', MinMaxScaler(copy=True, feature_range=(0, 1))), ('SKB', SelectKBest(k=6, score_func=<function f_classif at 0x0000000007B63F98>)), ('PCA', PCA(copy=True, n_components=4, whiten=False)), ('NB', GaussianNB())])\n",
      "\tAccuracy: 0.85564\tPrecision: 0.49256\tRecall: 0.34750\tF1: 0.40751\tF2: 0.36925\n",
      "\tTotal predictions: 14000\tTrue positives:  695\tFalse positives:  716\tFalse negatives: 1305\tTrue negatives: 11284\n",
      "\n",
      "done in 5.306s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# PCA\n",
    "pca = PCA()\n",
    "#Pipeline\n",
    "pipeline = Pipeline([('scale',mm_scaler),('SKB',SelectKBest()),('PCA',PCA()),('NB', GaussianNB())])\n",
    "# clf's parameters\n",
    "parameters = {'SKB__k':[5,6],\n",
    "              'PCA__n_components':[2,3,4]\n",
    "             }\n",
    "#GridSearchCV\n",
    "gs = GridSearchCV(pipeline, parameters, cv=sss, scoring='f1')\n",
    "gs.fit(features, labels)\n",
    "\n",
    "clf_NB = gs.best_estimator_\n",
    "tester.test_classifier(clf_NB, my_dataset, new_features_list)\n",
    "print \"done in %0.3fs\" % (time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this classifier, there are many parameters that I could tune. Because of heavy computation, I selected ony 5 parameters: criterion, splitter, min_samples_split, max_depth, max_leaf_nodes. Those parameters will be put in the cross-validation with feature selection and component analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scale', MinMaxScaler(copy=True, feature_range=(0, 1))), ('SKB', SelectKBest(k=5, score_func=<function f_classif at 0x0000000007B63F98>)), ('PCA', PCA(copy=True, n_components=2, whiten=False)), ('DT', DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=25,\n",
      "            max_features=None, max_leaf_nodes=30, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'))])\n",
      "\tAccuracy: 0.82007\tPrecision: 0.35639\tRecall: 0.32200\tF1: 0.33832\tF2: 0.32834\n",
      "\tTotal predictions: 14000\tTrue positives:  644\tFalse positives: 1163\tFalse negatives: 1356\tTrue negatives: 10837\n",
      "\n",
      "done in 669.987s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# PCA\n",
    "pca = PCA()\n",
    "#Pipeline\n",
    "pipeline = Pipeline([('scale',mm_scaler),('SKB',SelectKBest()),('PCA',PCA()),('DT', DecisionTreeClassifier())])\n",
    "# clf's parameters\n",
    "parameters = {'DT__criterion': ['gini','entropy'],\n",
    "              'DT__splitter':['best','random'],\n",
    "              'DT__min_samples_split':[2,10,20],\n",
    "              'DT__max_depth':[10,15,20,25,30],\n",
    "              'DT__max_leaf_nodes':[5,10,30],\n",
    "              'SKB__k':[5,6],\n",
    "              'PCA__n_components':[2,3,4]}\n",
    "#GridSearchCV\n",
    "gs = GridSearchCV(pipeline, parameters, cv=sss, scoring='f1')\n",
    "gs.fit(features, labels)\n",
    "\n",
    "clf_DT = gs.best_estimator_\n",
    "tester.test_classifier(clf_DT, my_dataset, new_features_list)\n",
    "print \"done in %0.3fs\" % (time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I tried to to make an machine system that can built the best model from data. In machine system, chosen learning algorithm goes with multiple parameters. All those parameters will effect the quality of data models. However, it is not easy to find the correct values of those parameters. Thus, tuning is one of the most important in machine learning. This step will help us to obtain optimal values to complete learning task in the best way as possible. The \"best\" of those values is dependent on our criteria. For instance, I mainly tuned parameters of Naive Bayes and Decision Tree models to obtain at least 0.3 in both precision and recall in this project. \n",
    "\n",
    "In two final results, Naive Bayes provide better score of precision and recall. It is logical since the Enron dataset is pretty small so simpler model will be easily fit. In conclusion, Naive Bayes model is my final model for this Enron fraud classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = clf_NB\n",
    "dump_classifier_and_data(clf, my_dataset, new_features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Validation and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose of this project is to identify the best learning model for Enron dataset. From previous analysis, there are more than one approach to build that model. In learning approach, one of process is parameter tuning. The \"best\" choice of parameters requires validation. Validation estimates how well my model has been trained. Validation includes splitting Enron data into multiple train/test sets. This step is essential because it limits problem such as data overfitting or underfitting. In this project, I have used \"train_test_split\" and \"StratifiedShuffleSplit\" for re-sample Enron data. \"TrainTestSplit\" created small dataset to choose the appropriate classifiers. \"StratifiedShuffleSplit\" was used for cross-validation of optimal parameters.\n",
    "\n",
    "Instead of using simpler cross-validation methods, I picked \"StratifiedShuffleSplit\" for my final learning algorithm. Enron dataset is quite small so \"StratifiedShuffleSplit\" allows to create randomly multiple training and test sets then averages the results over all the tests. Moreover, Enrone dataset has unbalanced classes where number of POIs is greatly smaller than number of non-POIs. \"StratifiedShuffleSplit\" makes sure the ratio of POI/non-POIs is the same in the training and test sets as it was in the larger dataset. \n",
    "\n",
    "I used precision and recall to estimate my model properties. The precision measures a classifiers exactness and the recall measures a classifiers completeness. In small and unbalanced like Enron dataset, both of them are more important than accuracy. If validation is not good, my model will fall in high level of error type I and II. We always want to have high chance to catch criminal but ignore innocent person.\n",
    "\n",
    "The good estimators for my Enron classification model is the one which has the score of precision and recall above 0.3. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "This Enron dataset is an unbalaned data where POIs is greatly samller than non-POIs. There are 3 outliers and many of missing values in each features of data point. I have removed all of outliers and replaced missing values by '0' during data auditing.\n",
    "\n",
    "On the other hands, I optimized Feature Selection by creating two new features: \"fraction_to_poi\" and \"fraction_from_poi\". According to the impact scores, I have selected 6 features to build my learning model. One of them was my new engineered feature. Without it, I have lower score in term of precision and recall. \n",
    "\n",
    "For learning model, I validated a series of common classifers. Based on my F1-score, I picked two classifiers: Naive Bayes and Decisition Tree. My final model is Naive Bayes model in which I receive the better score of precision (0.49) and recall (0.34) after parameter tuning."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
